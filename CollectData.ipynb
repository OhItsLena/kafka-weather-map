{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b52af4a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#https://ipython.readthedocs.io/en/stable/config/extensions/autoreload.html?highlight=autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from Kafka import KafkaWriter\n",
    "from OpenWeatherMap import OpenWeatherMap\n",
    "from confluent_kafka import Consumer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NoBrokersAvailable",
     "evalue": "NoBrokersAvailable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNoBrokersAvailable\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m/Users/hammerer/Documents/DHBW4/Big Data Programming/kafka-weather-map/CollectData.ipynb Zelle 2\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/hammerer/Documents/DHBW4/Big%20Data%20Programming/kafka-weather-map/CollectData.ipynb#W1sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m openWeatherMap \u001b[39m=\u001b[39m OpenWeatherMap()\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/hammerer/Documents/DHBW4/Big%20Data%20Programming/kafka-weather-map/CollectData.ipynb#W1sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m kafkaForecast \u001b[39m=\u001b[39m KafkaWriter(\u001b[39m'\u001b[39;49m\u001b[39mweather.forecast\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/hammerer/Documents/DHBW4/Big%20Data%20Programming/kafka-weather-map/CollectData.ipynb#W1sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m kafkaCleaned \u001b[39m=\u001b[39m KafkaWriter(\u001b[39m'\u001b[39m\u001b[39mweather.cleaned\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/hammerer/Documents/DHBW4/Big%20Data%20Programming/kafka-weather-map/CollectData.ipynb#W1sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mformat_date\u001b[39m(dt: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mstr\u001b[39m:\n",
      "File \u001b[0;32m~/Documents/DHBW4/Big Data Programming/kafka-weather-map/Kafka.py:25\u001b[0m, in \u001b[0;36mKafkaWriter.__init__\u001b[0;34m(self, kafka_topic)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, kafka_topic: \u001b[39mstr\u001b[39m):\n\u001b[1;32m     24\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mproducer \u001b[39m=\u001b[39m KafkaProducer(\n\u001b[1;32m     26\u001b[0m             bootstrap_servers\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkafka_bootstrap_server,\n\u001b[1;32m     27\u001b[0m             key_serializer\u001b[39m=\u001b[39;49m\u001b[39mstr\u001b[39;49m\u001b[39m.\u001b[39;49mencode,\n\u001b[1;32m     28\u001b[0m             value_serializer\u001b[39m=\u001b[39;49m\u001b[39mlambda\u001b[39;49;00m v: json\u001b[39m.\u001b[39;49mdumps(v)\u001b[39m.\u001b[39;49mencode(\u001b[39m'\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m'\u001b[39;49m))\n\u001b[1;32m     29\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkafka_topic \u001b[39m=\u001b[39m kafka_topic\n\u001b[1;32m     31\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m ve:\n\u001b[1;32m     32\u001b[0m         \u001b[39m# might hapen when the bootstrap server is unreachable\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/kafka3/producer/kafka.py:383\u001b[0m, in \u001b[0;36mKafkaProducer.__init__\u001b[0;34m(self, **configs)\u001b[0m\n\u001b[1;32m    380\u001b[0m reporters \u001b[39m=\u001b[39m [reporter() \u001b[39mfor\u001b[39;00m reporter \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig[\u001b[39m'\u001b[39m\u001b[39mmetric_reporters\u001b[39m\u001b[39m'\u001b[39m]]\n\u001b[1;32m    381\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_metrics \u001b[39m=\u001b[39m Metrics(metric_config, reporters)\n\u001b[0;32m--> 383\u001b[0m client \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconfig[\u001b[39m'\u001b[39;49m\u001b[39mkafka_client\u001b[39;49m\u001b[39m'\u001b[39;49m](\n\u001b[1;32m    384\u001b[0m     metrics\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_metrics, metric_group_prefix\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mproducer\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m    385\u001b[0m     wakeup_timeout_ms\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconfig[\u001b[39m'\u001b[39;49m\u001b[39mmax_block_ms\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    386\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconfig)\n\u001b[1;32m    388\u001b[0m \u001b[39m# Get auto-discovered version from client if necessary\u001b[39;00m\n\u001b[1;32m    389\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig[\u001b[39m'\u001b[39m\u001b[39mapi_version\u001b[39m\u001b[39m'\u001b[39m] \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/kafka3/client_async.py:244\u001b[0m, in \u001b[0;36mKafkaClient.__init__\u001b[0;34m(self, **configs)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig[\u001b[39m'\u001b[39m\u001b[39mapi_version\u001b[39m\u001b[39m'\u001b[39m] \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    243\u001b[0m     check_timeout \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig[\u001b[39m'\u001b[39m\u001b[39mapi_version_auto_timeout_ms\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m/\u001b[39m \u001b[39m1000\u001b[39m\n\u001b[0;32m--> 244\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig[\u001b[39m'\u001b[39m\u001b[39mapi_version\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcheck_version(timeout\u001b[39m=\u001b[39;49mcheck_timeout)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/kafka3/client_async.py:927\u001b[0m, in \u001b[0;36mKafkaClient.check_version\u001b[0;34m(self, node_id, timeout, strict)\u001b[0m\n\u001b[1;32m    924\u001b[0m \u001b[39m# Timeout\u001b[39;00m\n\u001b[1;32m    925\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    926\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m--> 927\u001b[0m     \u001b[39mraise\u001b[39;00m Errors\u001b[39m.\u001b[39mNoBrokersAvailable()\n",
      "\u001b[0;31mNoBrokersAvailable\u001b[0m: NoBrokersAvailable"
     ]
    }
   ],
   "source": [
    "openWeatherMap = OpenWeatherMap()\n",
    "kafkaForecast = KafkaWriter('weather.forecast')\n",
    "kafkaCleaned = KafkaWriter('weather.cleaned')\n",
    "\n",
    "def format_date(dt: str) -> str:\n",
    "    return datetime.fromtimestamp(float(dt)).strftime('%d.%m.%Y %H:%M')\n",
    "\n",
    "\n",
    "# load 'locations.json' into a json-object and return it\n",
    "def load_locations() -> json:\n",
    "    with open('locations.json', mode='r') as file:\n",
    "        return json.load(file)\n",
    "\n",
    "def get_transformed_forecast(cities: json) -> json:\n",
    "    forecasts = []\n",
    "\n",
    "    for key in cities:\n",
    "        city = cities[key]\n",
    "        forecast = openWeatherMap.get_forecast(city)\n",
    "\n",
    "        value = {\n",
    "            'city': forecast['city']['name'],\n",
    "            'weather': []\n",
    "        }\n",
    "\n",
    "        preds = []\n",
    "        for pred in forecast['list']:\n",
    "            preds.append({\n",
    "                'dt': pred['dt_txt'],\n",
    "                'temp': pred['main']['temp']\n",
    "            })\n",
    "        value['weather'] = preds\n",
    "\n",
    "        forecasts.append(value)\n",
    "\n",
    "    return json.dumps({'cities':forecasts})\n",
    "\n",
    "# for each location, query openWeatherMap for the 5-day forecast and \n",
    "# store the the returned values in Kafka\n",
    "def collect_forecast_data() -> None:\n",
    "    try:\n",
    "        print(\"Starting collection ...\")\n",
    "\n",
    "        cities = load_locations()\n",
    "\n",
    "        while True:\n",
    "            forecasts = get_transformed_forecast(cities)\n",
    "            dt = format_date(datetime.timestamp(datetime.now()))\n",
    "\n",
    "            kafkaForecast.store(dt, forecasts)\n",
    "\n",
    "            print(f\"Weather data collected at {dt}!\")\n",
    "\n",
    "            time.sleep(60)\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"... collection stopped!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69089f34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting collection ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Node 3 connection failed -- refreshing metadata\n",
      "Node 2 connection failed -- refreshing metadata\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weather data collected at 23.08.2022 17:12!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Node 3 connection failed -- refreshing metadata\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... collection stopped!\n"
     ]
    }
   ],
   "source": [
    "collect_forecast_data()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "af6a7de25dd7bd9a9e288da6c3d15d5d500c51449326063643a18fc796b35585"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
